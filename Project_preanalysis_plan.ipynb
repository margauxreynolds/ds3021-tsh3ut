{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 3021 Project Pre-Analysis Plan (\"Methods\" Section of Final Paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Question\n",
    "\n",
    "The central question guiding my analysis is \"Which individuals are most likely to experience a stroke based on demographic and health characteristics?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an observation in your study?\n",
    "\n",
    "In this dataset, each observation represents a single individual. The data include both demographic information (such as age and gender) and clinical variables (such as hypertension, heart disease, BMI, average glucose level, and smoking status), as well as a binary target variable indicating whether the individual has experienced a stroke (1) or not (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you doing supervised or unsupervised learning? Classification or regression?\n",
    "\n",
    "This is a supervised learning problem because each individual in the dataset is labeled with a stroke outcome: 1 for stroke and 0 for no stroke. Since this outcome is binary, the task falls under classification rather than regression. The goal is to use a set of predictors (X) to accurately classify whether a stroke will occur (Y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What models or algorithms do you plan to use in your analysis? How?\n",
    "\n",
    "I plan to use two or three modeling strategies to predict stroke risk such as:\n",
    "\n",
    "Logistic Regression: This will serve as a baseline model due to its interpretability and simplicity. I will one-hot encode categorical variables (such as smoking status and work type), and standardize continuous variables (such as BMI and average glucose level) to improve model performance. Logistic regression will help estimate the marginal effect of each feature on the probability of stroke.\n",
    "\n",
    "Decision Tree Classifier: A non-linear, rule-based classifier will be used to model interactions between variables and capture complex relationships. Tree depth and other hyperparameters will be tuned to prevent overfitting. The decision tree will also offer insight into variable importance and decision pathways.\n",
    "\n",
    "Logistic Regression with PCA: To explore dimensionality reduction, I will apply PCA to the standardized numeric features and then fit a logistic regression model using the top principal components. This allows for a structured comparison between the full-feature logiostic regression and a compressed version, testing whether dimensionality reduction sacrifices performance.\n",
    "\n",
    "Each model will be trained and evaluated using the train-test aplit to ensure comparability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: How will you prepare the data specifically for your analysis? \n",
    "I will prepare the data by one-hot encoding categorical variables such as \"gender\", \"ever_married\", \"work_type\", \"Residence_type\", and \"smoking_status\", standardizing numeric features such as \"age\", \"avg_glucose_level\", and \"bmi\", and applying PCA to the numeric variables (for the PCA model only). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How will you know if your approach \"works\"? What does success mean?\n",
    "\n",
    "The models can be evaluated on the test set using several classification metrics such as accuracy (the overall rate of correct predictions), sensitivity/specificity and precision (to access false positives, false negatives, and true positives), F1 score (a harmonic mean of precision and sensivity/recall), confusion matrices (to visualize the distribution of prediction errors), and ROC-AUC (to evaluate model performance across all classification thresholds).\n",
    "\n",
    "A successfull model should not only correctly identify stroke cases but also avoid over-predicting them. Also, success means that the model performs will on the test set, not just the training data, indicating that it generalizes well to unseen data. If logistic regresssion with PCA achieves similar results to the full model, that would also indicate successful dimensionality reduction without sacrificing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: How will you communicate or present your results? \n",
    "\n",
    "Results could be communicated using tables comparing classification metrics discussed above across models, confusion matrices for each model to understand prediction breakdowns, ROC curves to visualize sensitivity/specificity trade-offs, feature importance plots from the decision tree, and coefficient tables from logistic regression. These visual and numerical summaries will help clarify why each model performed as it did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are weaknesses that you anticipate being an issue? How will you deal with them if they come up? If your approach fails, what might you learn from this unfortunate outcome?\n",
    "\n",
    "Several potential challenges/weaknesses could aries such as:\n",
    "Stroke cases imbalance: There are a lot more no stoke cases than stroke cases in the data, which could bias models towards the majority.\n",
    "Overfitting: Especially relevant for decision trees, I can use pruning strategies and limit tree depth.\n",
    "Multicollinearity: PCA may help address high correlation among numeric features.\n",
    "\n",
    "If none of the models perform better than chance, it may suggest that the features in the dataset are not strong predictors of stroke risk, or that the features require more complex transformations and interactions. In either case, I would look and analyze failure cases, continue to understand model limitations, and consider additional data that could improve prediction. Even if it fails, I'll learn about the challenges of health outcome prediction."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
